{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "JmIHSwq46aK0"
   },
   "source": [
    "# Dimcli open in colab badge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "ywx1JTDnjzTw"
   },
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/digital-science/dimensions-api-lab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open Dimensions API Lab In Google Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "VQ4p0oK8eplO"
   },
   "source": [
    "# Dimcli Install - Short Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "jlOIqrKjewJ1"
   },
   "source": [
    "A bunch of extra libraries are also installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "Qw8liuJs4bbQ"
   },
   "outputs": [],
   "source": [
    "# @markdown # Get the API library and login \n",
    "# @markdown Click the 'play' button on the left (or shift+enter) after entering your API credentials\n",
    "\n",
    "username = \"\" #@param {type: \"string\"}\n",
    "password = \"\" #@param {type: \"string\"}\n",
    "endpoint = \"https://app.dimensions.ai\" #@param {type: \"string\"}\n",
    "\n",
    "!pip install dimcli plotly tqdm -U --quiet\n",
    "\n",
    "# load common libraries\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm as progress\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "if not 'google.colab' in sys.modules:\n",
    "  # make js dependecies local / needed by html exports \n",
    "  from plotly.offline import init_notebook_mode\n",
    "  init_notebook_mode(connected=True)\n",
    "\n",
    "import dimcli\n",
    "from dimcli.shortcuts import *\n",
    "\n",
    "dimcli.login(username, password, endpoint)\n",
    "dsl = dimcli.Dsl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rMVf1PtXwhon"
   },
   "source": [
    "# Dimcli Install - Long Version with PSW hiding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "j6-0XQr5wgJO"
   },
   "outputs": [],
   "source": [
    "# @markdown # Get the API library and login \n",
    "# @markdown **Privacy tip**: leave the password blank and you'll be asked for it later. This can be handy on shared computers.\n",
    "username = \"\"  #@param {type: \"string\"}\n",
    "password = \"\"  #@param {type: \"string\"}\n",
    "endpoint = \"https://app.dimensions.ai\"  #@param {type: \"string\"}\n",
    "\n",
    "\n",
    "print(\"==\\nInstalling libraries..\")\n",
    "!pip install dimcli plotly_express -U --quiet \n",
    "import dimcli\n",
    "from dimcli.shortcuts import *\n",
    "\n",
    "#\n",
    "# load common libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from tqdm import tqdm_notebook as progressbar\n",
    "#\n",
    "# charts lib\n",
    "import plotly_express as px\n",
    "if not 'google.colab' in sys.modules:\n",
    "  # make js dependecies local / needed by html exports \n",
    "  from plotly.offline import init_notebook_mode\n",
    "  init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "\n",
    "# AUTHENTICATION \n",
    "# https://github.com/digital-science/dimcli#authentication\n",
    "#\n",
    "# == Google Colab users ==\n",
    "# If username/password not provided, the interactive setup assistant `dimcli --init` is invoked\n",
    "#\n",
    "# == Jupyter Notebook users == \n",
    "# If username/password not provided, try to use the global API credentials file.\n",
    "# To create one, open a terminal (File/New/Terminal) and run `dimcli --init` from there\n",
    "#  \n",
    "#\n",
    "print(\"==\\nLogging in..\")\n",
    "if username and password:\n",
    "  dimcli.login(username, password, endpoint)\n",
    "else:\n",
    "  if 'google.colab' in sys.modules:\n",
    "    print(\"Environment: Google Colab\")\n",
    "    if username and not password:\n",
    "      import getpass\n",
    "      password = getpass.getpass(prompt='Password: ')     \n",
    "      dimcli.login(username, password, endpoint)\n",
    "    else:\n",
    "      print(\"... launching interactive setup assistant\")\n",
    "      !dimcli --init    \n",
    "      dimcli.login()\n",
    "  else:\n",
    "    print(\"Environment: Jupyter Notebook\\n... looking for API credentials file\")\n",
    "    dimcli.login()\n",
    "\n",
    "dsl = dimcli.Dsl()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# data-saving utils \n",
    "#\n",
    "DATAFOLDER = \"extraction1\"\n",
    "if not os.path.exists(DATAFOLDER):\n",
    "  !mkdir $DATAFOLDER\n",
    "  print(f\"==\\nCreated data folder:\", DATAFOLDER + \"/\")\n",
    "#\n",
    "#\n",
    "def save_as_csv(df, save_name_without_extension):\n",
    "    \"usage: `save_as_csv(dataframe, 'filename')`\"\n",
    "    df.to_csv(f\"{DATAFOLDER}/{save_name_without_extension}.csv\", index=False)\n",
    "    print(\"===\\nSaved: \", f\"{DATAFOLDER}/{save_name_without_extension}.csv\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "4_uRsb__o0I9"
   },
   "source": [
    "# Dimcli Install - Newest version with PSW hiding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Y308RJhGo59i"
   },
   "outputs": [],
   "source": [
    "# @markdown # Get the API library and login \n",
    "# @markdown Note: on Google Colab you'll be asked to input credentials each time, so to prevent sharing them accidentally.\n",
    "!pip install dimcli --quiet \n",
    "\n",
    "import dimcli\n",
    "from dimcli.shortcuts import *\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "#\n",
    "\n",
    "print(\"==\\nLogging in..\")\n",
    "# https://github.com/digital-science/dimcli#authentication\n",
    "ENDPOINT = \"https://app.dimensions.ai\"\n",
    "if 'google.colab' in sys.modules:\n",
    "  import getpass\n",
    "  USERNAME = getpass.getpass(prompt='Username: ')\n",
    "  PASSWORD = getpass.getpass(prompt='Password: ')    \n",
    "  dimcli.login(USERNAME, PASSWORD, ENDPOINT)\n",
    "else:\n",
    "  USERNAME, PASSWORD  = \"\", \"\"\n",
    "  dimcli.login(USERNAME, PASSWORD, ENDPOINT)\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eq0nPOXNEBgo"
   },
   "source": [
    "# Dimcli Selector With Dropdowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "AhemUxl3IXMt"
   },
   "outputs": [],
   "source": [
    "# tip \n",
    "# the subjects dropdown can be generated via \n",
    "# str([\"%s\" % s for s in  sorted(dimcli.G.categories('category_for')) if len(s.split()[0]) > 2])\n",
    "#\n",
    "\n",
    "start_year = 2015  #@param {type: \"slider\", min: 1980, max: 2020}\n",
    "end_year = 2019  #@param {type: \"slider\", min: 1980, max: 2020}\n",
    "subject1 = \"0911 Maritime Engineering\"  #@param ['0101 Pure Mathematics', '0102 Applied Mathematics', '0103 Numerical and Computational Mathematics', '0104 Statistics', '0105 Mathematical Physics', '0201 Astronomical and Space Sciences', '0202 Atomic, Molecular, Nuclear, Particle and Plasma Physics', '0203 Classical Physics', '0204 Condensed Matter Physics', '0205 Optical Physics', '0206 Quantum Physics', '0299 Other Physical Sciences', '0301 Analytical Chemistry', '0302 Inorganic Chemistry', '0303 Macromolecular and Materials Chemistry', '0304 Medicinal and Biomolecular Chemistry', '0305 Organic Chemistry', '0306 Physical Chemistry (incl. Structural)', '0307 Theoretical and Computational Chemistry', '0399 Other Chemical Sciences', '0401 Atmospheric Sciences', '0402 Geochemistry', '0403 Geology', '0404 Geophysics', '0405 Oceanography', '0406 Physical Geography and Environmental Geoscience', '0499 Other Earth Sciences', '0501 Ecological Applications', '0502 Environmental Science and Management', '0503 Soil Sciences', '0599 Other Environmental Sciences', '0601 Biochemistry and Cell Biology', '0602 Ecology', '0603 Evolutionary Biology', '0604 Genetics', '0605 Microbiology', '0606 Physiology', '0607 Plant Biology', '0608 Zoology', '0699 Other Biological Sciences', '0701 Agriculture, Land and Farm Management', '0702 Animal Production', '0703 Crop and Pasture Production', '0704 Fisheries Sciences', '0705 Forestry Sciences', '0706 Horticultural Production', '0707 Veterinary Sciences', '0799 Other Agricultural and Veterinary Sciences', '0801 Artificial Intelligence and Image Processing', '0802 Computation Theory and Mathematics', '0803 Computer Software', '0804 Data Format', '0805 Distributed Computing', '0806 Information Systems', '0807 Library and Information Studies', '0899 Other Information and Computing Sciences', '0901 Aerospace Engineering', '0902 Automotive Engineering', '0903 Biomedical Engineering', '0904 Chemical Engineering', '0905 Civil Engineering', '0906 Electrical and Electronic Engineering', '0907 Environmental Engineering', '0908 Food Sciences', '0909 Geomatic Engineering', '0910 Manufacturing Engineering', '0911 Maritime Engineering', '0912 Materials Engineering', '0913 Mechanical Engineering', '0914 Resources Engineering and Extractive Metallurgy', '0915 Interdisciplinary Engineering', '0999 Other Engineering', '1001 Agricultural Biotechnology', '1002 Environmental Biotechnology', '1003 Industrial Biotechnology', '1004 Medical Biotechnology', '1005 Communications Technologies', '1006 Computer Hardware', '1007 Nanotechnology', '1099 Other Technology', '1101 Medical Biochemistry and Metabolomics', '1102 Cardiorespiratory Medicine and Haematology', '1103 Clinical Sciences', '1104 Complementary and Alternative Medicine', '1105 Dentistry', '1106 Human Movement and Sports Science', '1107 Immunology', '1108 Medical Microbiology', '1109 Neurosciences', '1110 Nursing', '1111 Nutrition and Dietetics', '1112 Oncology and Carcinogenesis', '1113 Ophthalmology and Optometry', '1114 Paediatrics and Reproductive Medicine', '1115 Pharmacology and Pharmaceutical Sciences', '1116 Medical Physiology', '1117 Public Health and Health Services', '1199 Other Medical and Health Sciences', '1201 Architecture', '1202 Building', '1203 Design Practice and Management', '1205 Urban and Regional Planning', '1299 Other Built Environment and Design', '1301 Education Systems', '1302 Curriculum and Pedagogy', '1303 Specialist Studies In Education', '1399 Other Education', '1401 Economic Theory', '1402 Applied Economics', '1403 Econometrics', '1499 Other Economics', '1501 Accounting, Auditing and Accountability', '1502 Banking, Finance and Investment', '1503 Business and Management', '1504 Commercial Services', '1505 Marketing', '1506 Tourism', '1507 Transportation and Freight Services', '1601 Anthropology', '1602 Criminology', '1603 Demography', '1604 Human Geography', '1605 Policy and Administration', '1606 Political Science', '1607 Social Work', '1608 Sociology', '1699 Other Studies In Human Society', '1701 Psychology', '1702 Cognitive Sciences', '1799 Other Psychology and Cognitive Sciences', '1801 Law', '1899 Other Law and Legal Studies', '1901 Art Theory and Criticism', '1902 Film, Television and Digital Media', '1903 Journalism and Professional Writing', '1904 Performing Arts and Creative Writing', '1905 Visual Arts and Crafts', '1999 Other Studies In Creative Arts and Writing', '2001 Communication and Media Studies', '2002 Cultural Studies', '2003 Language Studies', '2004 Linguistics', '2005 Literary Studies', '2099 Other Language, Communication and Culture', '2101 Archaeology', '2102 Curatorial and Related Studies', '2103 Historical Studies', '2199 Other History and Archaeology', '2201 Applied Ethics', '2202 History and Philosophy of Specific Fields', '2203 Philosophy', '2204 Religion and Religious Studies', '2299 Other Philosophy and Religious Studies']\n",
    "subject2 = \"None\"  #@param ['None', '0101 Pure Mathematics', '0102 Applied Mathematics', '0103 Numerical and Computational Mathematics', '0104 Statistics', '0105 Mathematical Physics', '0201 Astronomical and Space Sciences', '0202 Atomic, Molecular, Nuclear, Particle and Plasma Physics', '0203 Classical Physics', '0204 Condensed Matter Physics', '0205 Optical Physics', '0206 Quantum Physics', '0299 Other Physical Sciences', '0301 Analytical Chemistry', '0302 Inorganic Chemistry', '0303 Macromolecular and Materials Chemistry', '0304 Medicinal and Biomolecular Chemistry', '0305 Organic Chemistry', '0306 Physical Chemistry (incl. Structural)', '0307 Theoretical and Computational Chemistry', '0399 Other Chemical Sciences', '0401 Atmospheric Sciences', '0402 Geochemistry', '0403 Geology', '0404 Geophysics', '0405 Oceanography', '0406 Physical Geography and Environmental Geoscience', '0499 Other Earth Sciences', '0501 Ecological Applications', '0502 Environmental Science and Management', '0503 Soil Sciences', '0599 Other Environmental Sciences', '0601 Biochemistry and Cell Biology', '0602 Ecology', '0603 Evolutionary Biology', '0604 Genetics', '0605 Microbiology', '0606 Physiology', '0607 Plant Biology', '0608 Zoology', '0699 Other Biological Sciences', '0701 Agriculture, Land and Farm Management', '0702 Animal Production', '0703 Crop and Pasture Production', '0704 Fisheries Sciences', '0705 Forestry Sciences', '0706 Horticultural Production', '0707 Veterinary Sciences', '0799 Other Agricultural and Veterinary Sciences', '0801 Artificial Intelligence and Image Processing', '0802 Computation Theory and Mathematics', '0803 Computer Software', '0804 Data Format', '0805 Distributed Computing', '0806 Information Systems', '0807 Library and Information Studies', '0899 Other Information and Computing Sciences', '0901 Aerospace Engineering', '0902 Automotive Engineering', '0903 Biomedical Engineering', '0904 Chemical Engineering', '0905 Civil Engineering', '0906 Electrical and Electronic Engineering', '0907 Environmental Engineering', '0908 Food Sciences', '0909 Geomatic Engineering', '0910 Manufacturing Engineering', '0911 Maritime Engineering', '0912 Materials Engineering', '0913 Mechanical Engineering', '0914 Resources Engineering and Extractive Metallurgy', '0915 Interdisciplinary Engineering', '0999 Other Engineering', '1001 Agricultural Biotechnology', '1002 Environmental Biotechnology', '1003 Industrial Biotechnology', '1004 Medical Biotechnology', '1005 Communications Technologies', '1006 Computer Hardware', '1007 Nanotechnology', '1099 Other Technology', '1101 Medical Biochemistry and Metabolomics', '1102 Cardiorespiratory Medicine and Haematology', '1103 Clinical Sciences', '1104 Complementary and Alternative Medicine', '1105 Dentistry', '1106 Human Movement and Sports Science', '1107 Immunology', '1108 Medical Microbiology', '1109 Neurosciences', '1110 Nursing', '1111 Nutrition and Dietetics', '1112 Oncology and Carcinogenesis', '1113 Ophthalmology and Optometry', '1114 Paediatrics and Reproductive Medicine', '1115 Pharmacology and Pharmaceutical Sciences', '1116 Medical Physiology', '1117 Public Health and Health Services', '1199 Other Medical and Health Sciences', '1201 Architecture', '1202 Building', '1203 Design Practice and Management', '1205 Urban and Regional Planning', '1299 Other Built Environment and Design', '1301 Education Systems', '1302 Curriculum and Pedagogy', '1303 Specialist Studies In Education', '1399 Other Education', '1401 Economic Theory', '1402 Applied Economics', '1403 Econometrics', '1499 Other Economics', '1501 Accounting, Auditing and Accountability', '1502 Banking, Finance and Investment', '1503 Business and Management', '1504 Commercial Services', '1505 Marketing', '1506 Tourism', '1507 Transportation and Freight Services', '1601 Anthropology', '1602 Criminology', '1603 Demography', '1604 Human Geography', '1605 Policy and Administration', '1606 Political Science', '1607 Social Work', '1608 Sociology', '1699 Other Studies In Human Society', '1701 Psychology', '1702 Cognitive Sciences', '1799 Other Psychology and Cognitive Sciences', '1801 Law', '1899 Other Law and Legal Studies', '1901 Art Theory and Criticism', '1902 Film, Television and Digital Media', '1903 Journalism and Professional Writing', '1904 Performing Arts and Creative Writing', '1905 Visual Arts and Crafts', '1999 Other Studies In Creative Arts and Writing', '2001 Communication and Media Studies', '2002 Cultural Studies', '2003 Language Studies', '2004 Linguistics', '2005 Literary Studies', '2099 Other Language, Communication and Culture', '2101 Archaeology', '2102 Curatorial and Related Studies', '2103 Historical Studies', '2199 Other History and Archaeology', '2201 Applied Ethics', '2202 History and Philosophy of Specific Fields', '2203 Philosophy', '2204 Religion and Religious Studies', '2299 Other Philosophy and Religious Studies']\n",
    "connector = \"or\"  #@param ['or', 'and']\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "ytkMDIJ-FuOO"
   },
   "source": [
    "# Dimcli looped query using `chunks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "sa23Be4JeCA-"
   },
   "source": [
    "For example, if we are extracting several researchers infos based on a long list of IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Y9fPwKLgF0rR"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dimcli.shortcuts import chunks_of\n",
    "from tqdm import tqdm_notebook as pbar\n",
    "\n",
    "query = \"\"\"search researchers where id in {} return researchers[id+last_grant_year+total_grants] limit 1000\"\"\"\n",
    "\n",
    "ids = [\"ur.011177563061.78\", \"ur.011177563061.55\", \"ur.011177563061.10\"] # etc..  \n",
    "\n",
    "results = []\n",
    "for chunk in pbar(list(chunks_of(list(ids), 400))):\n",
    "    q = dsl.query(query.format(json.dumps(chunk)))\n",
    "    results += q.researchers\n",
    "\n",
    "# save to a dataframe for further analysis..\n",
    "df = pd.DataFrame().from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "BB-GZhqfOql_"
   },
   "source": [
    "# Dimcli nested looped query with `chunks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "3TBIqh2sOv97"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from dimcli.shortcuts import chunks_of\n",
    "from tqdm import tqdm_notebook as pbar\n",
    "\n",
    "queries = {\n",
    "    \"Publications\" : \"\"\"search publications where research_orgs in {} return publications limit 1\"\"\" ,\n",
    "    \"Grants\" : \"\"\"search grants where research_orgs in {} return grants limit 1\"\"\" ,\n",
    "    \"Clinical Trials\" : \"\"\"search clinical_trials where organizations in {} return clinical_trials limit 1\"\"\" ,\n",
    "    \"Patents\" : \"\"\"search patents where assignees in {} return patents limit 1\"\"\" ,\n",
    "    \"Policy Documents\" : \"\"\"search policy_documents where publisher_org in {} return policy_documents limit 1\"\"\" ,\n",
    "    \"Altmetric\" : \"\"\"search publications where research_orgs in {} and altmetric > 0 return publications limit 1\"\"\" ,\n",
    "}\n",
    "\n",
    "gridids = ['grid.461628.f', 'grid.418010.c', 'grid.461634.2'] # and more...\n",
    "#\n",
    "results = []\n",
    "#\n",
    "loop1 = pbar(list(queries))\n",
    "#\n",
    "for doctype in loop1:\n",
    "  loop1.set_description(\"Processing %s\" % doctype)\n",
    "  #\n",
    "  loop2 = pbar(list(chunks_of(list(gridids), 20)))\n",
    "  #\n",
    "  tot = 0\n",
    "  for chunk in loop2: \n",
    "    loop2.set_description(\"Processing Grid IDs..\")\n",
    "    q = queries[doctype].format(json.dumps(chunk))\n",
    "    #\n",
    "    data = dsl.query(q, verbose=False)\n",
    "    #\n",
    "    tot += data.count_total\n",
    "    time.sleep(1)\n",
    "  results.append({'doctype': doctype, 'count' : tot})\n",
    "\n",
    "\n",
    "# save to a dataframe\n",
    "df = pd.DataFrame().from_dict(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "nAPtbSQ3VuNr"
   },
   "source": [
    "# Print libraries versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "qHc2OrD2VuNs",
    "outputId": "3398b32e-7f0d-4b31-9db0-a28c36c1ee58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries versions:\n",
      "---\n",
      "=> pandas :  1.0.3\n",
      "=> plotly :  4.6.0\n",
      "=> dimcli :  0.6.7.2\n",
      "=> tqdm :  4.43.0\n"
     ]
    }
   ],
   "source": [
    "# print versions of libraries \n",
    "print(\"Libraries versions:\\n---\")\n",
    "import pkg_resources\n",
    "for lib in [\"pandas\", \"plotly\", \"dimcli\", \"tqdm\"]:\n",
    "    print(\"=>\", lib, \": \", pkg_resources.get_distribution(lib).version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "OBzo3g-tCTUN"
   },
   "source": [
    "# Plotly chart with basic stats about publication authors or affiliations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "SKfr4ZAYgZyK"
   },
   "source": [
    "Extract all authors from a list of publications and obtain basic stats about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "YE_PhokkCTAz"
   },
   "outputs": [],
   "source": [
    "from dimcli import dslquery\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "authors = dslquery(\"\"\"search publications for \"bmw\" return publications limit 1000\"\"\").as_dataframe_authors()\n",
    "researchers = authors.query(\"researcher_id!=''\")\n",
    "# build df\n",
    "df = pd.DataFrame({\n",
    "    'measure' : ['Authors in total (non unique)', 'Authors with a researcher ID', 'Authors with a researcher ID (unique)'],\n",
    "    'count' : [len(authors), len(researchers), researchers['researcher_id'].nunique()],\n",
    "})\n",
    "px.bar(df, x=\"measure\", y=\"count\", title=f\"Author stats for {journal_title} (from {start_year})\")\n",
    "\n",
    "\n",
    "#\n",
    "# for affiliations \n",
    "#\n",
    "affiliations = dslquery(\"\"\"search publications for \"bmw\" return publications limit 1000\"\"\").as_dataframe_authors_affiliations()\n",
    "gridaffiliations = affiliations.query(\"aff_id != ''\")\n",
    "df = pd.DataFrame({\n",
    "    'measure' : ['Affiliations in total (non unique)', 'Affiliations with a GRID ID', 'Affiliations with a GRID ID (unique)'],\n",
    "    'count' : [len(affiliations), len(gridaffiliations), gridaffiliations['aff_id'].nunique()],\n",
    "})\n",
    "px.bar(df, x=\"measure\", y=\"count\", title=f\"Affiliations stats for {journal_title} (from {start_year})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "V5XQA7pUCNEH"
   },
   "source": [
    "# Dimcli chart with basic stats about publication affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "KyRib-ShCEIG"
   },
   "outputs": [],
   "source": [
    "affiliations = dsl.query(\"\"\"search publications for \"bmw\" return publications limit 1000\"\"\").as_dataframe_authors_affiliations()\n",
    "\n",
    "gridaffiliations = affiliations.query(\"aff_id != ''\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'measure' : ['Affiliations in total (non unique)', 'Affiliations with a GRID ID', 'Affiliations with a GRID ID (unique)'],\n",
    "    'count' : [len(affiliations), len(gridaffiliations), gridaffiliations['aff_id'].nunique()],\n",
    "})\n",
    "# requires plotly_express library\n",
    "px.bar(df, x=\"measure\", y=\"count\", title=f\"Affiliations stats for {journal_title} (from {start_year})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "PDDe12arx3Mp"
   },
   "source": [
    "# Plotly quick chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "OLE5W7bTx5q_"
   },
   "outputs": [],
   "source": [
    "!pip install plotly --quiet\n",
    "import plotly.express as px\n",
    "\n",
    "# bar chart \n",
    "px.bar(df, x=\"name\", y=\"funding\", hover_name=\"name\", color=\"country_name\")\n",
    "\n",
    "# scatter plot \n",
    "px.scatter(df, x=\"year\", y=\"times_cited\", color=\"type\", \n",
    "           hover_name=\"title\", \n",
    "           hover_data=['type', 'doi', 'year', 'times_cited', 'journal.title'], \n",
    "           height=600, title=\"Publications most cited by year of publication\")\n",
    "\n",
    "# with marginal data\n",
    "px.scatter(df, x=\"times_cited\", y=\"name\", \n",
    "           hover_name=\"name\", hover_data=['times_cited'],\n",
    "           marginal_x=\"histogram\", marginal_y=\"histogram\", \n",
    "           height=900, title=\"Research Areas VS Citations (marginal subplots = X/Y distribution)\")\n",
    "\n",
    "# sort data by tot count\n",
    "px.histogram(affiliations, x=\"aff_name\").update_xaxes(categoryorder=\"total descending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "69nnFemmixMa"
   },
   "source": [
    "# Plotly Export to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1579872682917,
     "user": {
      "displayName": "Michele Pasin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBu8LVjIGgontF2Wax51BoL5KFx8esezX3bUmaa0g=s64",
      "userId": "10309320684375994511"
     },
     "user_tz": 0
    },
    "id": "RKI7X8ETixMb",
    "outputId": "4ebd97ac-57c1-47b4-e03c-f2fe94da8d20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://community.plot.ly/t/plotly-express-plots-automatically-open-new-tabs-when-using-plotly-offline/24862\n",
    "\n",
    "# note: for image export you need extra libraries https://plot.ly/python/static-image-export/\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot \n",
    "\n",
    "iris = px.data.iris()\n",
    "scatter_plot = px.scatter(iris, x=\"sepal_width\", y=\"sepal_length\")\n",
    "\n",
    "plot(scatter_plot, filename = 'filename.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "pzUeLbXniSTq"
   },
   "source": [
    "# Plotly Create Multiple Charts at the same time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "meJ0XHTviYMU"
   },
   "outputs": [],
   "source": [
    "# https://plot.ly/python/creating-and-updating-figures/\n",
    "# https://plot.ly/python/renderers/\n",
    "\n",
    "fig1 = px.bar(iris, x=\"sepal_width\", y=\"sepal_length\", color=\"petal_width\")\n",
    "fig2 = px.bar(iris, x=\"sepal_width\", y=\"petal_length\", facet_col=\"species\")\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "JlmdfclCDCGn"
   },
   "source": [
    "# Plotly fill in missing years with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "tSrTXhDwDGyM"
   },
   "outputs": [],
   "source": [
    "yrange = [dfbyjournal['year'].min(), dfbyjournal['year'].max()]\n",
    "all_years = [x for x in range(yrange[0], yrange[1]+1)]  # add one to make sure max value is included\n",
    "\n",
    "def add_missing_years_per_journal(ajournal):\n",
    "    global dfbyjournal\n",
    "    # list of years that already have values \n",
    "    known_years = list(dfbyjournal[dfbyjournal[\"journal.title\"] == ajournal]['year'])\n",
    "    l = [] \n",
    "    for x in all_years:\n",
    "        if x not in known_years:\n",
    "            l.append({'journal.title' : ajournal , 'year' : x, 'times_cited': 0, 'totdois' : 0, 'totcitations' : 0})\n",
    "    # note about pandas append: appending a full list once per journal is much faster! \n",
    "    dfbyjournal = dfbyjournal.append(l, ignore_index=True )\n",
    "    \n",
    "\n",
    "# now call the routine for all journals\n",
    "# \n",
    "journals = dfbyjournal['journal.title'].value_counts().index.tolist()\n",
    "for j in journals:\n",
    "    add_missing_years_per_journal(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "yNepcO9Zjl7P"
   },
   "source": [
    "# Zip file archive and download from Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "2zRMsI6CjlJI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# zip up all files to make download easier\n",
    "import zipfile\n",
    "import os \n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file))\n",
    "\n",
    "zipf = zipfile.ZipFile('output.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('out/', zipf)\n",
    "zipf.close()\n",
    "\n",
    "\n",
    "# try to download from colab: sometimes it fails hence print a message\n",
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "  time.sleep(2)\n",
    "  files.download('output.zip') \n",
    "except:\n",
    "  print(\"Google Colab couldn't download - please try again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cHcahK64VlkN"
   },
   "source": [
    "# Pandas Create Dataframe\n",
    "\n",
    "Reminder about [tidy data](http://www.jeannicholashould.com/tidy-data-in-python.html)\n",
    "\n",
    "* Each variable forms a column and contains values\n",
    "* Each observation forms a row\n",
    "* Each type of observational unit forms a table\n",
    "\n",
    "A few definitions:\n",
    "\n",
    "* Variable: A measurement or an attribute. Height, weight, sex, etc.\n",
    "* Value: The actual measurement or attribute. 152 cm, 80 kg, female, etc.\n",
    "* Observation: All values measure on the same unit. Each person.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "ABA-VbkoVlkP"
   },
   "outputs": [],
   "source": [
    "# With empty columns\n",
    "df = pd.DataFrame(columns=['A','B','C','D','E','F','G'])\n",
    "\n",
    "# by columns\n",
    "df = pd.DataFrame({\n",
    "    'name' : ['val1', 'val2', 'etc..'],\n",
    "    'category' : ['val1', 'val2', 'etc..'],\n",
    "})\n",
    "\n",
    "# by rows (records)\n",
    "df = pd.DataFrame.from_dict([\n",
    "    {'name': 'val1', 'category' : 'val1' },\n",
    "    {'name': 'val1', 'category' : 'val1' },\n",
    "    ...\n",
    "})\n",
    "\n",
    "# from a simple dict\n",
    "d = {'location': list(results.keys()), 'count': list(results.values())}\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "\n",
    "\n",
    "# from JSON\n",
    "pd.read_json('file.json', orient='columns') # for rows, use 'records' \n",
    "pd.to_json('out.json', orient='columns')\n",
    "\n",
    "# from CSV\n",
    "df = pd.read_csv(\"/tmp/tmp07wuam09/data/cereal.csv\")\n",
    "\n",
    "# create DF from Series\n",
    "counts = pubs_citing['journal.title'].value_counts()\n",
    "df = counts.to_frame().reset_index() # reset index can mess up column names\n",
    "df = df.rename(columns= {0: 'list'})\n",
    "df.index.name = 'index'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "mo0Gw2kfi_t4"
   },
   "source": [
    "# Pandas Describe and Count Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "mn53-Mnvi_t7"
   },
   "outputs": [],
   "source": [
    "# Return a tuple representing the dimensionality of the DataFrame.\n",
    "df.shape\n",
    "\n",
    "# Return an int representing the number of axes / array dimensions.\n",
    "df.ndim\n",
    "\n",
    "# This returns a Series with the data type of each column. \n",
    "# The result’s index is the original DataFrame’s columns. Columns with mixed types are stored with the object dtype.\n",
    "df.dtypes\n",
    "\n",
    "# the 'describe' method returns basic statistic for all columns of a dataframe\n",
    "df.describe(include='all')\n",
    "\n",
    "# Count distict values, use nunique:\n",
    "df['hID'].nunique()\n",
    "\n",
    "# Count only non-null values, use count:\n",
    "df['hID'].count()\n",
    "\n",
    "# Count total values including null values, use size attribute:\n",
    "df['hID'].size\n",
    "\n",
    "# this will show you the distinct element and their number of occurence.\n",
    "df['race'].value_counts()\n",
    "# only top ten\n",
    "df['race'].value_counts()[:10]\n",
    "# max value\n",
    "df['race'].value_counts().idxmax()\n",
    "# get he values not the counts\n",
    "df['race'].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "# count missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Frequency count based on two columns (variables)\n",
    "df.groupby([\"Group\", \"Size\"]).size()\n",
    "df.groupby([\"Group\", \"Size\"]).size().reset_index(name=\"Freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "TZDFzxIdCFRf"
   },
   "source": [
    "# Pandas get Dataframe Cell Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "bsQgftLRCFKF"
   },
   "outputs": [],
   "source": [
    "In [15]: df = pandas.DataFrame(numpy.random.randn(5,3),columns=list('ABC'))\n",
    "\n",
    "In [16]: df\n",
    "Out[16]: \n",
    "          A         B         C\n",
    "0 -0.074172 -0.090626  0.038272\n",
    "1 -0.128545  0.762088 -0.714816\n",
    "2  0.201498 -0.734963  0.558397\n",
    "3  1.563307 -1.186415  0.848246\n",
    "4  0.205171  0.962514  0.037709\n",
    "\n",
    "In [17]: df.iat[0,0]\n",
    "Out[17]: -0.074171888537611502\n",
    "\n",
    "In [18]: df.at[0,'A']\n",
    "Out[18]: -0.074171888537611502\n",
    "\n",
    "# OR\n",
    "\n",
    "val = d2['col_name'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "xVgRt9BivYhK"
   },
   "source": [
    "# Pandas Select and Rename Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "0AHuO0itvYhS"
   },
   "outputs": [],
   "source": [
    "# select by position\n",
    "df.iloc[2] \n",
    "\n",
    "# label based indexing\n",
    "df.loc['index_label_1'] \n",
    "\n",
    "# Select rows based on cell values and update\n",
    "df.loc[df['journal'].isnull(), \"journal\"] = \"unknown\"\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# Rename columns using a dictionary to map values\n",
    "# Rename the Area columnn to 'place_name'\n",
    "data = data.rename(columns={\"Area\": \"place_name\"})\n",
    "\n",
    "# Again, the inplace parameter will change the dataframe without assignment\n",
    "data.rename(columns={\"Area\": \"place_name\"}, inplace=True)\n",
    "\n",
    "# Rename multiple columns in one go with a larger dictionary\n",
    "data.rename(\n",
    "    columns={\n",
    "        \"Area\": \"place_name\",\n",
    "        \"Y2001\": \"year_2001\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Rename all columns using a function, e.g. convert all column names to lower case:\n",
    "data.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rx_iUH-VwGGV"
   },
   "source": [
    "# Pandas Subset Dataframe via Slicing or Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "JhtdGm_SwGGX"
   },
   "outputs": [],
   "source": [
    "# Create a new DF by selecting columns\n",
    "df2 = df[['id', 'issue', 'pages', 'title', 'type', 'volume', 'year']]\n",
    "\n",
    "\n",
    "# from list\n",
    " df[df['A'].isin([3, 6])]\n",
    "# negative version\n",
    "df[~df['A'].isin([3, 6])]\n",
    "\n",
    "# with query\n",
    "df.query(' column_a == [\"val1\", \"val2\", ...]', inplace=True)\n",
    "df.query(\"type=='article'\")\n",
    "# query with variable\n",
    "my_symbol = 'BUD US'\n",
    "df.query(\"Symbol=='{0}'\".format(my_symbol))\n",
    "\n",
    "# if we have a list, it needs to be turned into a str first, then it's possible to use `str.contains`\n",
    "patents[patents['publication_ids'].apply(lambda x: ','.join(map(str, x))).str.contains(\"pub.1032163135\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "lYHlvbFtxEQK"
   },
   "source": [
    "# Pandas Modify Dataframe Rows / Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "eO3PACgWxDo_"
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df.drop(['author_affiliations'], axis=1, inplace=True)\n",
    "\n",
    "# drop column with missing values\n",
    "# Drop the rows where at least one element is missing.\n",
    "df.dropna()\n",
    "\n",
    "# Drop the columns where at least one element is missing.\n",
    "df.dropna(axis='columns')\n",
    "\n",
    "#Drop the rows where all elements are missing.\n",
    "df.dropna(how='all')\n",
    "\n",
    "#Keep only the rows with at least 2 non-NA values.\n",
    "df.dropna(thresh=2)\n",
    "\n",
    "#Define in which columns to look for missing values.\n",
    "df.dropna(subset=['name', 'born'])\n",
    "\n",
    "#Keep the DataFrame with valid entries in the same variable.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "# Drop empty values rows, after replacing empty strings\n",
    "df['FOR'].replace('', np.nan, inplace=True)\n",
    "#\n",
    "df.dropna(subset=['FOR'], inplace=False).head()\n",
    "\n",
    "# replace with empty list (can't be done with 'replace')\n",
    "for row in df.loc[df.ids.isnull(), 'ids'].index:\n",
    "    df.at[row, 'ids'] = []\n",
    "\n",
    "#    \n",
    "#\n",
    "# Drop rows based on values\n",
    "df = df[df.col != \"val\"]    \n",
    "    \n",
    "    \n",
    "    \n",
    "#\n",
    "#\n",
    "# Add new column to existing dataframe\n",
    "# Use the original df1 indexes to create the series:\n",
    "df1['e'] = pd.Series(np.random.randn(sLength), index=df1.index)\n",
    "\n",
    "# Declare a list that is to be converted into a column \n",
    "address = ['Delhi', 'Bangalore', 'Chennai', 'Patna'] \n",
    "df['Address'] = address \n",
    "\n",
    "# change column order\n",
    "df = df[['mean', '0', '1', '2', '3']]\n",
    "#You can get the list of columns with:\n",
    "cols = list(df.columns.values)\n",
    "\n",
    "#\n",
    "#\n",
    "# fill in empty values\n",
    "# fill everywhere, returns a frame\n",
    "ddf.fillna(0) \n",
    "# this returns a series, not a frame!\n",
    "ddf['FOR'].fillna(\"aaa\") # NOTE doesn't save anything! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "kCZk1opEzO7U"
   },
   "source": [
    "# Pandas Add Columns by Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "hhGxhl4HzO7X"
   },
   "outputs": [],
   "source": [
    "# add new column \n",
    "df['M1_list'] = df['M1'].apply(lambda x: x.split(\",\"))\n",
    "# use apply with two cols // axis=1\n",
    "test['search_url'] = test.apply(lambda x: google_url(x['first_name'] + \" \" +x['last_name'] ), axis=1)\n",
    "\n",
    "\n",
    "# transpose axix\n",
    "df3 = df.transpose()\n",
    "\n",
    "\n",
    "#\n",
    "# group by\n",
    "#\n",
    "# The groupby output will have an index or multi-index on rows corresponding to your chosen grouping variables. \n",
    "# To avoid setting this index, pass “as_index=False” to the groupby operation.\n",
    "df2 = df.groupby('year', as_index=False)\n",
    "df2.groups.keys()\n",
    "group2003 = df2.get_group(2003)\n",
    "group2003.head()\n",
    "\n",
    "# counting on groupby https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "df.groupby('year', as_index=False)['id'].count()\n",
    "\n",
    "# Groupby and sum only one column https://stackoverflow.com/questions/38985053/pandas-groupby-and-sum-only-one-column\n",
    "df_by_concept = df.groupby('concept', as_index=False)['score'].sum()\n",
    "\n",
    "# Using groupby to filter items that occur more than once\n",
    "df_top_journals = df.groupby('journal.title').filter(lambda x: len(x) > 3)\n",
    "\n",
    "# Add a column that counts a variable in groupby\n",
    "df['count'] = df.groupby('group')['group'].transform('count')\n",
    "\n",
    "# add new column by counting unique instances in another column than the grouping one\n",
    "gridaffiliations[\"tot_pubs\"] = gridaffiliations.groupby(['aff_id'])['pub_id'].transform('nunique')\n",
    "\n",
    "# group by two variables\n",
    "gridaffiliations.groupby(['aff_id', 'pub_id']).count()\n",
    "\n",
    "#\n",
    "# Splitting dictionary/list inside a Pandas Column into Separate Columns\n",
    "\n",
    "df['dict_column'].apply(pd.Series) # return new df only for those cols\n",
    "\n",
    "pd.concat([df.drop(['dict_column'], axis=1), df['dict_column'].apply(pd.Series)], axis=1) # add to existing df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "C4RCb6TguV96"
   },
   "source": [
    "# Pandas Add Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "ezzgxOQ5uZfz"
   },
   "outputs": [],
   "source": [
    "# by appending a DICT\n",
    "# https://www.w3resource.com/python-exercises/pandas/python-pandas-data-frame-exercise-26.php\n",
    "\n",
    "d = {'col1': [1, 4, 3, 4, 5], 'col2': [4, 5, 6, 7, 8], 'col3': [7, 8, 9, 0, 1]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "print('After add one row:')\n",
    "data = {'col1': 10, 'col2': 11, 'col3': 12}\n",
    "df = df.append(data, ignore_index=True) # ignore index preserves the original index\n",
    "\n",
    "\n",
    "\n",
    "# appending more than one dict\n",
    "l = []\n",
    "for x in source_data:\n",
    "  l.append({'col1': x[0], 'col2': x[1], 'col3': x[2]}) # include all cols!\n",
    "df = df.append(data, ignore_index=True) \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# gen df by adding rows\n",
    "# https://stackoverflow.com/questions/10715965/add-one-row-to-pandas-dataframe\n",
    "rows_list = []\n",
    "for row in input_rows:\n",
    "\n",
    "        dict1 = {\"col1\": 'val', \"col2\": \"val\"}\n",
    "        rows_list.append(dict1)\n",
    "\n",
    "df = pd.DataFrame(rows_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "DdVvf1pPy-iq"
   },
   "source": [
    "# Pandas Sort and Remove Duplicates Dataframe\n",
    "\n",
    "https://thispointer.com/pandas-sort-rows-or-columns-in-dataframe-based-on-values-using-dataframe-sort_values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "dEwTLgaAy-it"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "# Arguments :\n",
    "\n",
    "# by : A string or list of strings basically either column names or index labels based on which sorting will be done.\n",
    "# axis : If axis is 0, then name or list of names in by argument will be considered as column names. Default is 0\n",
    "# If axis is 1, then name or list of names in by argument will be considered as row index labels\n",
    "# ascending : If True sort in ascending else sort in descending order. Default is True\n",
    "# inplace : If True, perform operation in-place in Dataframe\n",
    "# na_position : Decides the position of NaNs after sorting i.e. irst puts NaNs at the beginning, last puts NaNs at the end\n",
    "# Default value is ‘first’\n",
    "\n",
    "# sort in place and update the index as well\n",
    "df.sort_values(by=[\"year\"], inplace=True) \n",
    "df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# dropping ALL duplicate values \n",
    "df.drop_duplicates(subset =\"First Name\", \n",
    "                     keep = 'first', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "4KVVD4Gyv0bI"
   },
   "source": [
    "# Pandas Iterate Dataframe\n",
    "\n",
    "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "KDz1PFlov0bK"
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row['c1'], row['c2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "OV-NZO-B0Wtp"
   },
   "source": [
    "# Pandas Merge and Aggregate Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "FMCRHiXX0Wts"
   },
   "outputs": [],
   "source": [
    "df2 = pd.merge(dfy, dfyears_nl, how='outer')\n",
    "\n",
    "# concenate dataframes simply add new rows at the bottom\n",
    "res = df1.append([df2, df3])\n",
    "# then usually sort and reset index for visualizations etc...\n",
    "res.rename(columns={'id':'years'}, inplace=True)\n",
    "res.sort_values(by=\"years\", inplace=True)\n",
    "res.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# melt\n",
    "formatted_df = pd.melt(df,\n",
    "                       [\"religion\"],  # the columns to keep as is\n",
    "                       var_name=\"income\",  # the columnn grouping all melted columns \n",
    "                       value_name=\"freq\")  # the column counting the objects melted\n",
    "formatted_df = formatted_df.sort_values(by=[\"religion\"])\n",
    "formatted_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "0i4B7IOf0tPD"
   },
   "source": [
    "# Pandas flatten JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "H3LWTdQD0vmI"
   },
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "dfjournals = json_normalize(data.publications) # returns a new column journal.title\n",
    "dfjournals.reset_index()\n",
    "\n",
    "#\n",
    "# normalize a nested object\n",
    "#\n",
    "# ensure that all pubs have a valid (empty, even) key\n",
    "for x in data.publications:\n",
    "    if not 'FOR' in x:\n",
    "        x['FOR'] = \"\"\n",
    "    else:\n",
    "        x['FOR'] = [{'name' : x['name'][5:]} for x in x['FOR']] # also remove the digit prefix to improve legibility\n",
    "# then\n",
    "json_normalize(data.publications, record_path=['FOR'], meta=[\"doi\", \"title\"], errors='ignore', record_prefix='for_').head()\n",
    "\n",
    "\n",
    "# recursive applications\n",
    "import json\n",
    "json_normalize(json.loads(df_aff1.to_json(orient='records')), record_path=['affiliations'], \n",
    "               meta=['id', 'researcher_id', 'first_name', 'last_name'], record_prefix='aff_')\n",
    "\n",
    "\n",
    "# unpack a dict value into separate columns\n",
    "# https://stackoverflow.com/questions/50512188/unpack-dictionary-from-pandas-column\n",
    "concepts['concepts_scores'].dropna().apply(pd.Series)\n",
    "\n",
    "# enrich original df with unpacked columns - need to dropna on original df first\n",
    "concepts.dropna(subset=['concepts_scores']).drop('concepts_scores', 1).assign(**concepts['concepts_scores'].dropna().apply(pd.Series))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "bDmB_DeBBnhr"
   },
   "source": [
    "# Pandas Update Data in Frame While Iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "-h-UWiIFBr2B"
   },
   "outputs": [],
   "source": [
    "print(\"\\n===\\nCounting clinical_trials for each publication...\")\n",
    "\n",
    "# build str column version for checking inclusion\n",
    "clinical_trials['publication_ids_str'] = clinical_trials['publication_ids'].apply(lambda x: ','.join(map(str, x)))                                 \n",
    "def get_clinical_trials_per_pub(pubid):\n",
    "    global clinical_trials\n",
    "    # turn list into str and check content in one line\n",
    "    return clinical_trials[clinical_trials['publication_ids_str'].str.contains(pubid)]['id']\n",
    "\n",
    "# using 'AT' method\n",
    "publications['clinical_trials_count'] = 0\n",
    "publications['clinical_trials_ids'] = \"\"\n",
    "for index, row in pbar(publications.iterrows(), total=publications.shape[0]):\n",
    "    match_clinical_trials = get_clinical_trials_per_pub(row['id'])\n",
    "    publications.at[index,'clinical_trials_count'] = len(match_clinical_trials)\n",
    "    publications.at[index,'clinical_trials_ids'] = list(match_clinical_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "lvigrh-DKQSc"
   },
   "source": [
    "# Python strip punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "19UXaHIiKT0z"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "s = \"&&**^^hello\"\n",
    "s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "G_3_qVZMvYe4"
   },
   "source": [
    "# Pandas avoid setting with copy warning\n",
    "\n",
    "The warning was generated because we have chained two indexing operations together. This is made easier to spot because we’ve used square brackets twice, but the same would be true if we used other access methods such as .bidderrate, .loc[], .iloc[], .ix[] and so on.\n",
    "\n",
    "* https://www.dataquest.io/blog/settingwithcopywarning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "UePH6PevvbwF"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# explicit chaining\n",
    "#\n",
    "data[data.bidder == 'parakeet2004']['bidderrate'] = 100\n",
    "# instead we do \n",
    "data.loc[data.bidder == 'parakeet2004', 'bidderrate'] = 100\n",
    "\n",
    "#\n",
    "# hidden chaining\n",
    "#\n",
    "winners = data.loc[data.bid == data.price]\n",
    "winners.loc[304, 'bidder'] = 'therealname' # => warning\n",
    "# instead we do\n",
    "winners = data.loc[data.bid == data.price].copy()\n",
    "winners.loc[304, 'bidder'] = 'therealname' # => works!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DimcliSnippets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
